# 多线程 threading

Python中的多线程是一种实现并发执行多个任务的技术。

在 CPython 解释器中，全局解释器锁（Global Interpreter Lock, GIL）的存在，多线程并不能实现真正的并行计算（即同一时间在多个CPU核心上执行Python字节码），如果你想让你的应用更好地利用多核心计算机的计算资源，推荐你使用`multiprocessing`或 `concurrent.futures.ProcessPoolExecutor`。 

但它仍然适用于以下场景：

1. **I/O密集型任务**：当程序的主要瓶颈在于等待输入输出操作（如文件读写、网络请求等）时，多线程可以有效提升效率。在等待I/O操作完成时，线程可以被挂起，让其他线程继续执行，从而提高整体的响应速度。

2. **异步任务处理**：多线程可以用来处理后台任务或非阻塞式操作，使得用户界面或其他任务可以保持流畅。



Python提供了几个关键模块来支持多线程编程：

- **`threading`模块**：这是Python中最常用的线程管理模块，提供了Thread类来创建线程，Lock、RLock、Condition等类来进行线程间的同步，以及Queue（队列）类来实现线程安全的数据交换。在较低级的模块 `_thread` 基础上建立较高级的线程接口。

- **`queue`模块**：提供线程间通信的安全队列，包括FIFO（先进先出）、LIFO（后进先出）和优先级队列。

- **线程同步工具**：为了防止数据竞争和不一致，可以使用锁（Lock）、信号量（Semaphore）、条件变量（Condition）等同步原语来控制线程对共享资源的访问。

几点注意：

- **GIL的影响**：由于GIL的存在，即使在多核处理器上，Python的纯Python代码也通常不会看到CPU并行处理带来的性能提升。对于计算密集型任务，多进程（multiprocessing模块）或者使用其他没有GIL限制的语言（如C扩展）可能是更好的选择。

- **上下文切换开销**：频繁的线程上下文切换可能会引入额外的性能开销，因此合理设计线程数量和任务分配至关重要。

- **死锁与竞态条件**：编写多线程程序时，要特别小心处理资源的竞争，避免出现死锁和竞态条件等问题。

- **守护线程**：Python中的线程可以设置为守护线程（daemon），这意味着当主线程结束时，守护线程也会自动终止，无需手动管理。

理解并正确运用这些概念和工具，可以帮助你在Python中有效地利用多线程编程。





这个模块提供的带有 `acquire()` 和 `release()` 方法的对象，可以被用作 `with` 语句的上下文管理器。当进入语句块时 `acquire()` 方法会被调用，退出语句块时 `release()` 会被调用。

现在 `Lock` 、 `RLock` 、 `Condition` 、 `Semaphore` 和 `BoundedSemaphore` 对象可以用作 with 语句的上下文管理器。





## 函数和常量

这个模块定义了以下关键函数和常量，用于管理和控制线程操作：

1. **threading.active_count()**
   - 返回当前存活的 Thread 对象数量，与 `enumerate()` 函数输出的列表长度相同。
2. **threading.current_thread()**
   - 返回当前执行线程的 Thread 对象。若线程非 threading 模块创建，则返回一个受限的虚拟线程对象。
3. **threading.excepthook(args, /)**
   - 处理由 `Thread.run()` 方法引发且未被捕获的异常。`args` 参数包含异常类型、值、回溯信息及引发异常的线程。可重载此函数以自定义异常处理，注意避免由此产生的引用循环和线程复活问题。
4. **threading.get_ident()**
   - 返回当前线程的唯一标识符，为非零整数，用于如线程数据存储的场景。
5. **threading.get_native_id()**
   - 提供当前线程的系统原生ID，适用于需要跨进程唯一识别线程的情况。支持平台包括Windows、FreeBSD、Linux等。
6. **threading.enumerate()**
   - 列表形式返回所有当前活动的 Thread 对象，涵盖守护线程、主线程及虚拟线程。
7. **threading.main_thread()**
   - 特指程序启动时创建的主线程对象。
8. **threading.settrace(func)**
   - 为threading模块起始的所有线程设置跟踪函数，函数会在每个线程的 `run()` 调用前应用。
9. **threading.setprofile(func)**
   - 同上，但设置的是性能分析函数。
10. **threading.stack_size([size])**
    - 查询或设置新线程的堆栈大小。支持的平台包括Windows和具备POSIX线程的系统。
11. **threading.TIMEOUT_MAX**
    - 表示阻塞函数（如 `Lock.acquire()`, `RLock.acquire()`, `Condition.wait()` 等）中可接受的最大超时时间，超过此值将引发 `OverflowError`。

这些函数和常量共同构成了Python中使用threading模块进行多线程编程的基础工具集。





## 线程本地数据

线程本地数据是特定线程的数据。管理线程本地数据，只需要创建一个 local （或者一个子类型）的实例并在实例中储存属性：

```python
mydata = threading.local()
mydata.x = 1
```

在不同的线程中，实例的值会不同。



```python
import threading

# 定义一个ThreadLocal对象
thread_local_data = threading.local()


def worker(num):
    # 为当前线程设置数据
    thread_local_data.value = num
    print(f"Thread {threading.current_thread().name}: value = {thread_local_data.value}")


# 创建并启动几个线程
threads = []
for i in range(5):
    t = threading.Thread(target=worker, args=(i,))
    threads.append(t)
    t.start()

# 等待所有线程完成
for t in threads:
    t.join()

# 注意：这里不能直接访问thread_local_data.value，因为它在主线程中没有被赋值

"""
Thread Thread-1: value = 0
Thread Thread-2: value = 1
Thread Thread-3: value = 2
Thread Thread-4: value = 3
Thread Thread-5: value = 4
"""
```



## 线程对象 Thread

当线程对象一旦被创建，其活动必须通过调用线程的 start() 方法开始。 这会在独立的控制线程中发起调用 run() 方法。

一旦线程活动开始，该线程会被认为是 '存活的' 。当它的 run() 方法终结了（不管是正常的还是抛出未被处理的异常），就不是'存活的'。 is_alive() 方法用于检查线程是否存活。

其他线程可以调用一个线程的 join() 方法。这会阻塞调用该方法的线程，直到被调用 join() 方法的线程终结。

线程有名字。名字可以传递给构造函数，也可以通过 name 属性读取或者修改。

如果 run() 方法引发了异常，则会调用 threading.excepthook() 来处理它。 在默认情况下，threading.excepthook() 会静默地忽略 SystemExit。

一个线程可以被标记成一个“守护线程”。 这个标志的意义是，当剩下的线程都是守护线程时，整个 Python 程序将会退出。 初始值继承于创建线程。 这个标志可以通过 daemon 特征属性或者 daemon 构造器参数来设置。

注解 守护线程在程序关闭时会突然关闭。他们的资源（例如已经打开的文档，数据库事务等等）可能没有被正确释放。如果你想你的线程正常停止，设置他们成为非守护模式并且使用合适的信号机制，例如： Event。
有个 "主线程" 对象；这对应Python程序里面初始的控制线程。它不是一个守护线程。

"虚拟线程对象" 是可以被创建的。这些是对应于“外部线程”的线程对象，它们是在线程模块外部启动的控制线程，例如直接来自C代码。虚拟线程对象功能受限；他们总是被认为是存活的和守护模式，不能被 join() 。因为无法检测外来线程的终结，它们永远不会被删除。



`Thread`类用于创建和管理线程。其构造函数的参数及其描述如下：

```python
class threading.Thread(group=None, target=None, name=None, args=(), kwargs={}, *, daemon=None)
```

- **group**: （应设为None）- 此参数目前保留未来扩展使用，用于可能的`ThreadGroup`类实现。当前版本中，应始终传递`None`作为此参数的值。

- **target**: （默认为None）- 这是一个可调用对象，即当线程启动后将调用的函数。如果设为`None`，则新线程不会执行任何函数，仅简单地启动然后立即结束。常见的用法是传递一个函数名或是一个绑定方法的对象。

- **name**: （默认为"Thread-N"）- 设置线程的名字，其中"N"是一个递增的十进制数，用于生成唯一名称。自定义此参数可以帮助在日志记录或调试时更容易识别各个线程。

- **args**: （默认为()）- 一个元组，包含了传递给`target`函数的位置参数。允许你为线程任务指定具体的输入值。

- **kwargs**: （默认为{}）- 一个字典，包含了传递给`target`函数的关键字参数。这为函数调用提供了更多的灵活性，可以通过关键字指定参数值。

- **daemon**: （默认为None）- 此参数用于设定线程是否为守护线程（后台线程）。如果设为`True`，则当主线程结束时，无论守护线程是否还在运行，都会被强制终止。如果设为`False`或保持默认值`None`，则线程会正常执行，直到其任务完成。如果设为`None`，线程将继承创建它的线程的守护状态。这个参数是从Python 3.3版本开始加入的。



当子类化`Thread`并重写构造函数时，确保首先调用基类的构造函数`Thread.__init__()`，以正确初始化线程的基本属性。通过这些参数，你可以灵活地定义线程的行为，包括指定线程执行的任务、名称、传递给任务的参数，以及线程的守护状态。



### 方法与属性

- `start()`
  - 启动线程活动，使线程开始执行。
  - 只能被调用一次，重复调用会抛出 `RuntimeError`。
- `run()`
  - 线程活动的主要方法，可被子类重写以定义线程执行的具体任务。
  - 默认实现会调用构造时指定的 `target` 函数（如有提供），并传入 `args` 和 `kwargs`。
- `join(timeout=None)`
  - 阻塞调用线程，直到被调用线程结束或超时。
  - 若提供 `timeout` 参数，超时后方法返回，无论目标线程是否结束。
  - 要检测超时，需检查线程是否存活（使用 `is_alive()`）。
- `name`
  - 线程的名称，用于识别，可通过直接赋值修改。
  - 初始值由构造函数设定，格式如 "Thread-N"。
- `ident`
  - 线程的标识符，线程启动后为非零整数，线程未启动或结束后可能被复用。
- `native_id`
  - 线程的系统原生ID，线程启动后为非负整数，可用于全局唯一标识线程，直到线程终止。
- `is_alive()`
  - 判断线程是否仍在运行，`run()` 开始至结束期间返回 `True`。
- `daemon`
  - 布尔值，表示线程是否为守护线程。守护线程随着主线程结束而结束，须在 `start()` 之前设置。



### 创建Thread对象并传递回调函数

```python
import threading
import time


def my_function(arg1, arg2):
    time.sleep(2)
    print(f"线程 {threading.current_thread().name} 正在运行，参数为：{arg1}, {arg2}")


# 创建线程实例
my_thread = threading.Thread(target=my_function, args=(100, "World"), name="DemoThread")

# 设置为守护线程（可选）
# my_thread.daemon = True  # 设置True后，主线程结束，子线程也随之结束。

# 启动线程
my_thread.start()

print("主线程继续执行其他任务...")

# 如果需要，等待子线程结束
# my_thread.join()  # 使用join后，主线程会等待子线程结束，再执行后续代码。

print("所有任务完成。")
```



### 继承Thread类并重写run方法

```python
import threading
import time


class MyThread(threading.Thread):
    def __init__(self, arg1, arg2, name=None):
        super().__init__(name=name)
        self.arg1 = arg1
        self.arg2 = arg2

    def run(self):
        time.sleep(2)
        print(f"线程 {self.name} 正在运行，参数为：{self.arg1}, {self.arg2}")


# 创建线程实例
my_thread = MyThread(100, "World", name="DemoThread")

# 设置为守护线程（可选）
# my_thread.daemon = True  # 设置True后，主线程结束，子线程也随之结束。

# 启动线程
my_thread.start()

print("主线程继续执行其他任务...")

# 如果需要，等待子线程结束
# my_thread.join()  # 使用join后，主线程会等待子线程结束，再执行后续代码。

print("所有任务完成。")
```





## 互斥锁对象 Lock

原始锁是一个在锁定时不属于特定线程的同步基元组件。

原始锁处于 "锁定" 或者 "非锁定" 两种状态之一。它被创建时为非锁定状态。它有两个基本方法， `acquire()` 和 `release()` 。

当状态为非锁定时， acquire() 将状态改为 锁定 并立即返回。当状态是锁定时， acquire() 将阻塞至其他线程调用 release() 将其改为非锁定状态，然后 acquire() 调用重置其为锁定状态并返回。 release() 只在锁定状态下调用； 它将状态改为非锁定并立即返回。如果尝试释放一个非锁定的锁，则会引发 RuntimeError  异常。

当多个线程在 acquire() 等待状态转变为未锁定被阻塞，然后 release() 重置状态为未锁定时，只有一个线程能继续执行；至于哪个等待线程继续执行没有定义，并且会根据实现而不同。

所有方法的执行都是原子性的。



`Lock` 用于实现原始锁对象的类。一旦一个线程获得一个锁，会阻塞随后尝试获得锁的线程，直到它被释放；任何线程都可以释放它。

```python
class threading.Lock
```



### 方法

以下是关于Python `threading` 模块中锁操作方法的无序列表描述：

- **`acquire(blocking=True, timeout=-1)`**
  - 可以阻塞或非阻塞地获得锁。
  - 当调用时参数 *blocking* 设置为 `True` （缺省值），阻塞直到锁被释放，然后将锁锁定并返回 `True` 。
  - 在参数 *blocking* 被设置为 `False` 的情况下调用，将不会发生阻塞。如果调用时 *blocking* 设为 `True` 会阻塞，并立即返回 `False` ；否则，将锁锁定并返回 `True`。
  - 当浮点型 *timeout* 参数被设置为正值调用时，只要无法获得锁，将最多阻塞 *timeout* 设定的秒数。*timeout* 参数被设置为 `-1` 时将无限等待。当 *blocking* 为 false 时，*timeout* 指定的值将被忽略。
  - 如果成功获得锁，则返回 `True`，否则返回 `False` (例如发生 *超时* 的时候)。
- **`release()`**
  - **功能**：释放已经获取的锁。这个方法可以在任何线程中调用，不单指获得锁的线程。
  - 当锁被锁定，将它重置为未锁定，并返回。如果其他线程正在等待这个锁解锁而被阻塞，只允许其中一个允许。
  - 在未锁定的锁调用时，会引发`RuntimeError`异常。
  - 没有返回值。
- **`locked()`**
  - **目的**：检查锁当前是否被持有。
  - **返回**：锁被持有返回`True`，否则`False`。
  - **用途**：快速查询锁状态，不涉及获取或释放操作。

这些方法提供了基本的锁管理能力，确保线程间资源访问的同步与控制。



### 使用示例

```python
import threading
import time

# 创建一个Lock实例
lock = threading.Lock()

# 共享资源，此处为一个简单的计数器
counter = 0


def increment_counter(num_times):
    """
    一个模拟增加计数器的线程函数
    """
    global counter
    for _ in range(num_times):
        with lock:  # 使用with语句自动管理锁的获取与释放
            local_counter = counter
            local_counter += 1
            time.sleep(0.1)  # 模拟耗时操作，增加线程调度机会
            counter = local_counter
            print(f"Thread {threading.current_thread().name} incremented counter to {counter}")


# 创建并启动多个线程
threads = []
for i in range(3):
    t = threading.Thread(target=increment_counter, args=(2,))
    threads.append(t)
    t.start()

# 等待所有线程完成
for t in threads:
    t.join()

print(f"Final counter value: {counter}")


"""
Thread Thread-1 incremented counter to 1
Thread Thread-1 incremented counter to 2
Thread Thread-3 incremented counter to 3
Thread Thread-3 incremented counter to 4
Thread Thread-2 incremented counter to 5
Thread Thread-2 incremented counter to 6
Final counter value: 6
"""
```







## 递归锁对象 RLock

递归锁（Recursive Lock），也称为可重入锁（Reentrant Mutex），在多线程编程中扮演着重要的角色，其核心意义在于解决线程在递归调用或多次调用同一段加锁代码时可能出现的死锁问题。

重入锁是一个可以被同一个线程多次获取的同步基元组件。在内部，它在基元锁的锁定/非锁定状态上附加了 "所属线程" 和 "递归等级" 的概念。在锁定状态下，某些线程拥有锁 ； 在非锁定状态下， 没有线程拥有它。

若要锁定锁，线程调用其 acquire() 方法；一旦线程拥有了锁，方法将返回。若要解锁，线程调用 release() 方法。 acquire()/release() 对可以嵌套；只有最终 release() (最外面一对的 release() ) 将锁解开，才能让其他线程继续处理 acquire() 阻塞。



`RLock `实现了重入锁对象。重入锁必须由获取它的线程释放。一旦线程获得了重入锁，同一个线程再次获取它将不阻塞；线程必须在每次获取它时释放一次。

```python
class threading.RLock
```



### 方法

- `acquire`(*blocking=True*, *timeout=-1*)
  - 可以阻塞或非阻塞地获得锁。
  - 当无参数调用时： 如果这个线程已经拥有锁，递归级别增加一，并立即返回。否则，如果其他线程拥有该锁，则阻塞至该锁解锁。一旦锁被解锁(不属于任何线程)，则抢夺所有权，设置递归等级为一，并返回。如果多个线程被阻塞，等待锁被解锁，一次只有一个线程能抢到锁的所有权。在这种情况下，没有返回值。
  - 当发起调用时将 *blocking* 参数设为真值，则执行与无参数调用时一样的操作，然后返回 `True`。
  - 当发起调用时将 *blocking* 参数设为假值，则不进行阻塞。 如果一个无参数调用将要阻塞，则立即返回 `False`；在其他情况下，执行与无参数调用时一样的操作，然后返回 `True`。
  - 当发起调用时将浮点数的 *timeout* 参数设为正值时，只要无法获得锁，将最多阻塞 *timeout* 所指定的秒数。 如果已经获得锁则返回 `True`，如果超时则返回假值。

- `release`()
  - 释放锁，自减递归等级。如果减到零，则将锁重置为非锁定状态(不被任何线程拥有)，并且，如果其他线程正被阻塞着等待锁被解锁，则仅允许其中一个线程继续。如果自减后，递归等级仍然不是零，则锁保持锁定，仍由调用线程拥有。
  - 只有当前线程拥有锁才能调用这个方法。如果锁被释放后调用这个方法，会引起 RuntimeError 异常。
  - 没有返回值。



### 使用示例

```python
import threading

lock = threading.Lock()

lock.acquire()
print(f"第1次获取锁 -- {id(lock)}")
for i in range(3):
    lock.acquire()
    print(f"第2次获取锁 -- {id(lock)} -- {i}")
    lock.release()
lock.release()

"""
第1次获取锁 -- 20514816
(阻塞)
"""
```

以上使用互斥锁，会发生堵塞。如果使用递归锁，则不会出现阻塞。

```python
import threading

lock = threading.RLock()

lock.acquire()
print(f"第1次获取锁 -- {id(lock)}")
for i in range(3):
    lock.acquire()
    print(f"第2次获取锁 -- {id(lock)} -- {i}")
    lock.release()
lock.release()

"""
第1次获取锁 -- 29296640
第2次获取锁 -- 29296640 -- 0
第2次获取锁 -- 29296640 -- 1
第2次获取锁 -- 29296640 -- 2
"""
```



## 条件锁对象 Condition

`threading.Condition`对象是用于线程同步的一种机制，它允许一个或多个线程等待某个条件满足后再继续执行。条件对象总是与一个锁（`Lock`或`RLock`）关联，提供了在多线程环境下更精细的控制能力。

```python
class threading.Condition(lock=None)
```

实现条件变量对象的类。一个条件变量对象允许一个或多个线程在被其它线程所通知之前进行等待。

如果给出了非 None 的 lock 参数，则它必须为 Lock 或者 RLock 对象，并且它将被用作底层锁。否则，将会创建新的 RLock 对象，并将其用作底层锁。



### 方法

- **acquire(*args)**:
  - 请求条件变量关联的锁。如果没有提供锁，或者显式设置为`None`，条件对象会自动创建一个`RLock`作为底层锁。此方法会阻塞直到锁可用（如果`blocking=True`）。

- **release()**:
  - 释放底层锁。此方法调用底层锁的相应方法。没有返回值。

- **wait(timeout=None)**:
  - 使当前线程等待，直到被其他线程通过`notify()`或`notify_all()`唤醒，或者达到`timeout`（如果指定）。线程在等待时会释放锁，等待结束后重新获取锁。

- **wait_for(predicate, timeout=None)**:
  - 这是一个便利的方法，它结合了`wait()`和一个可调用的谓词（`predicate`）。`predicate`应该是一个没有参数的函数，当其返回`True`时，`wait_for()`结束等待。此方法同样会遵循`timeout`规则。

- **notify(n=1)**:
  - 唤醒一个或多个（取决于`n`的值）在`wait()`或`wait_for()`调用中阻塞的线程。被唤醒的线程必须重新竞争锁。

- **notify_all()**:
  - 唤醒所有在`wait()`或`wait_for()`调用中阻塞的线程。同样，被唤醒的线程需要重新竞争锁。

条件对象的工作原理是基于“条件等待”和“通知”机制。当线程发现某个条件不满足时，可以调用`wait()`方法，释放锁并挂起自己，直到其他线程改变了条件并通过`notify()`或`notify_all()`方法唤醒它们。这种设计有助于避免忙等待（busy-waiting），提高了效率并降低了CPU占用率。



### 使用示例

#### 简单的生产者消费者模型

```python
import threading
import time


class Buffer:
    def __init__(self):
        self.buffer = []
        self.max_size = 3
        self.condition = threading.Condition()

    def produce(self, item):
        with self.condition:
            while len(self.buffer) >= self.max_size:
                print("Buffer full, producer is waiting.")
                self.condition.wait()  # 生产者等待，直到通知
            self.buffer.append(item)
            print(f"Produced {item}, buffer size: {len(self.buffer)}")
            self.condition.notify_all()  # 通知所有等待的消费者

    def consume(self):
        with self.condition:
            while not self.buffer:
                print("Buffer empty, consumer is waiting.")
                self.condition.wait()  # 消费者等待，直到有产品或生产者通知
            item = self.buffer.pop(0)
            print(f"Consumed {item}, buffer size: {len(self.buffer)}")
            self.condition.notify_all()  # 通知所有等待的生产者


def producer(buffer):
    for i in range(10):
        buffer.produce(i)
        time.sleep(1)  # 模拟生产间隔


def consumer(buffer):
    for _ in range(10):
        buffer.consume()
        time.sleep(2)  # 模拟消费间隔


if __name__ == "__main__":
    buffer = Buffer()
    p = threading.Thread(target=producer, args=(buffer,))
    c = threading.Thread(target=consumer, args=(buffer,))

    p.start()
    c.start()

    p.join()
    c.join()

    print("All tasks completed.")

"""
Produced 0, buffer size: 1
Consumed 0, buffer size: 0
Produced 1, buffer size: 1
Produced 2, buffer size: 2
Consumed 1, buffer size: 1
Produced 3, buffer size: 2
Produced 4, buffer size: 3
Consumed 2, buffer size: 2
Produced 5, buffer size: 3
Buffer full, producer is waiting.
Consumed 3, buffer size: 2
Produced 6, buffer size: 3
Buffer full, producer is waiting.
Consumed 4, buffer size: 2
Produced 7, buffer size: 3
Buffer full, producer is waiting.
Consumed 5, buffer size: 2
Produced 8, buffer size: 3
Buffer full, producer is waiting.
Consumed 6, buffer size: 2
Produced 9, buffer size: 3
Consumed 7, buffer size: 2
Consumed 8, buffer size: 1
Consumed 9, buffer size: 0
All tasks completed.
"""
```

在这个示例中，我们定义了一个`Buffer`类，它包含一个缓冲区（列表）、最大容量限制、以及一个条件变量。`produce`方法代表生产者行为，当缓冲区满时，生产者线程会调用`condition.wait()`等待，直到有消费者消费了产品并调用`condition.notify_all()`通知。相反，`consume`方法代表消费者行为，当缓冲区空时，消费者线程也会等待，直到生产者添加了新产品并发出通知。

通过`Condition`，我们实现了生产者和消费者之间的协调，确保了资源的安全访问，避免了竞态条件。





#### 改成继承Thread的方式实现

```python
import threading
import time


class Buffer:
    def __init__(self):
        self.buffer = []
        self.max_size = 3
        self.condition = threading.Condition()

    def produce(self, item):
        with self.condition:
            while len(self.buffer) >= self.max_size:
                print("Buffer full, producer is waiting.")
                self.condition.wait()  
            self.buffer.append(item)
            print(f"Produced {item}, buffer size: {len(self.buffer)}")
            self.condition.notify_all()  

    def consume(self):
        with self.condition:
            while not self.buffer:
                print("Buffer empty, consumer is waiting.")
                self.condition.wait()  
            item = self.buffer.pop(0)
            print(f"Consumed {item}, buffer size: {len(self.buffer)}")
            self.condition.notify_all()  


class ProducerThread(threading.Thread):
    def __init__(self, buffer):
        super().__init__()
        self.buffer = buffer

    def run(self):
        for i in range(10):
            self.buffer.produce(i)
            time.sleep(1)  


class ConsumerThread(threading.Thread):
    def __init__(self, buffer):
        super().__init__()
        self.buffer = buffer

    def run(self):
        for _ in range(10):
            self.buffer.consume()
            time.sleep(2)  


if __name__ == "__main__":
    buffer = Buffer()
    producer_thread = ProducerThread(buffer)
    consumer_thread = ConsumerThread(buffer)

    producer_thread.start()
    consumer_thread.start()

    producer_thread.join()
    consumer_thread.join()

    print("All tasks completed.")
```



#### 使用wait_for示例

`wait_for(predicate, timeout=None)`方法是Python `threading.Condition` 类中的一个便捷方法，它允许线程等待直到给定的`predicate`（谓词函数）返回`True`，或者等待超时。下面是一个使用`wait_for`方法的简单示例，展示了如何在一个生产者消费者模型中确保消费者线程只在队列中有数据时才继续执行。

```python
import threading
import queue
import time

# 定义一个简单的队列
data_queue = queue.Queue()
condition = threading.Condition()

def producer():
    for i in range(5):
        time.sleep(1)  # 模拟生产数据的延迟
        item = f"Data {i}"
        with condition:
            data_queue.put(item)  # 生产数据
            print(f"Produced {item}")
            condition.notify_all()  # 通知等待的消费者线程

def consumer():
    while True:
        with condition:
            # 使用wait_for等待队列非空
            condition.wait_for(lambda: not data_queue.empty())
            item = data_queue.get()
            print(f"Consumed {item}")
            if data_queue.empty() and item == "Data 4":  # 如果是最后一个数据，退出循环
                break

# 创建线程
producer_thread = threading.Thread(target=producer)
consumer_thread = threading.Thread(target=consumer)

# 启动线程
producer_thread.start()
consumer_thread.start()

# 等待所有线程完成
producer_thread.join()
consumer_thread.join()

print("所有工作完成。")
```

在这个例子中，`producer`线程每隔一秒生成一个数据项并放入队列，同时调用`condition.notify_all()`通知可能在等待的消费者线程。消费者线程通过`condition.wait_for(lambda: not data_queue.empty())`等待队列中有数据可消费，一旦队列非空，谓词函数返回`True`，消费者线程就会继续执行，从队列中取出数据并打印，直到所有的数据都被消费完。`wait_for`方法的使用避免了消费者线程在队列为空时进行无效的循环检查，提高了效率。





## 信号量对象 Semaphore

一个信号量管理一个内部计数器，该计数器因 acquire() 方法的调用而递减，因 release() 方法的调用而递增。 计数器的值永远不会小于零；当 acquire() 方法发现计数器为零时，将会阻塞，直到其它线程调用 release() 方法。

可选参数 value 赋予内部计数器初始值，默认值为 1 。如果 value 被赋予小于0的值，将会引发 ValueError 异常。

```python
class threading.Semaphore(value=1)
```



### 方法

- `acquire`(*blocking=True*, *timeout=None*)
  - 获取一个信号量。
  - 在不带参数的情况下调用时：
    - 如果在进入时内部计数器的值大于零，则将其减一并立即返回 `True`。
    - 如果在进入时内部计数器的值为零，则将会阻塞直到被对 `release()` 的调用唤醒。 一旦被唤醒（并且计数器的值大于 0），则将计数器减 1 并返回 `True`。 每次对 `release()` 的调用将只唤醒一个线程。 线程被唤醒的次序是不可确定的。
  - 当发起调用时将 *blocking* 设为假值，则不进行阻塞。 如果一个无参数调用将要阻塞，则立即返回 `False`；在其他情况下，执行与无参数调用时一样的操作，然后返回 `True`。
  - 当发起调用时如果 *timeout* 不为 `None`，则它将阻塞最多 *timeout* 秒。 请求在此时段时未能成功完成获取则将返回 `False`。 在其他情况下返回 `True`。
- `release`()
  - 释放一个信号量，将内部计数器的值增加1。当计数器原先的值为0且有其它线程正在等待它再次大于0时，唤醒正在等待的线程。



### 有界信号量

```python
class threading.BoundedSemaphore(value=1)
```

有界信号量通过检查以确保它当前的值不会超过初始值。如果超过了初始值，将会引发 [`ValueError`](https://docs.python.org/zh-cn/3.8/library/exceptions.html#ValueError) 异常。在大多情况下，信号量用于保护数量有限的资源。如果信号量被释放的次数过多，则表明出现了错误。没有指定时， *value* 的值默认为1。

使用有界信号量能减少这种编程错误：信号量的释放次数多于其请求次数。



### 使用示例

```python
import threading
import time
from random import randint


def worker(semaphore, worker_id):
    with semaphore:
        print(f"Worker {worker_id} started. Time: {time.ctime()}")
        time.sleep(randint(1, 5))  # 模拟工作时间
        print(f"Worker {worker_id} finished. Time: {time.ctime()}")


if __name__ == "__main__":
    semaphore = threading.BoundedSemaphore(2)
    workers = []

    for i in range(3):
        t = threading.Thread(target=worker, args=(semaphore, i))
        workers.append(t)
        t.start()

    # 等待所有线程完成
    for t in workers:
        t.join()

    print("All workers have completed.")

"""
Worker 0 started. Time: Wed May 15 09:16:39 2024
Worker 1 started. Time: Wed May 15 09:16:39 2024
Worker 0 finished. Time: Wed May 15 09:16:40 2024
Worker 2 started. Time: Wed May 15 09:16:40 2024
Worker 2 finished. Time: Wed May 15 09:16:42 2024
Worker 1 finished. Time: Wed May 15 09:16:43 2024
All workers have completed.
"""
```





## 事件对象 Event

这是线程之间通信的最简单机制之一：一个线程发出事件信号，而其他线程等待该信号。

一个事件对象管理一个内部标志，调用 set() 方法可将其设置为true。调用 clear() 方法可将其设置为false。调用 wait() 方法将进入阻塞直到标志为true。这个标志初始时为false。

```python
class threading.Event
```



### 方法

- `is_set`()
  - 当且仅当内部旗标为时返回 `True`。

- `set`()
  - 将内部标志设置为true。所有正在等待这个事件的线程将被唤醒。当标志为true时，调用 wait() 方法的线程不会被被阻塞。
- `clear`()
  - 将内部标志设置为false。之后调用 wait() 方法的线程将会被阻塞，直到调用 set() 方法将内部标志再次设置为true。

- `wait`(*timeout=None*)
  - 阻塞线程直到内部变量为true。如果调用时内部标志为true，将立即返回。否则将阻塞线程，直到调用 set() 方法将标志设置为true或者发生可选的超时。

  - 当提供了timeout参数且不是 None 时，它应该是一个浮点数，代表操作的超时时间，以秒为单位（可以为小数）。
  - 当且仅当内部旗标在等待调用之前或者等待开始之后被设为真值时此方法将返回 True，也就是说，它将总是返回 True 除非设定了超时且操作发生了超时。



### 使用示例

一个生产者-消费者模型中使用`Event`来协调线程的执行流程：

```python
import threading
import time

class Producer(threading.Thread):
    def run(self):
        global event
        print("Producer: Preparing data...")
        time.sleep(2)  # 模拟数据准备过程
        print("Producer: Data ready!")
        event.set()  # 设置事件，通知消费者数据已准备好

class Consumer(threading.Thread):
    def run(self):
        global event
        print("Consumer: Waiting for data...")
        event.wait()  # 等待事件被设置
        print("Consumer: Data received! Processing...")

event = threading.Event()  # 初始化事件对象

producer = Producer()
consumer = Consumer()

producer.start()
consumer.start()

producer.join()  # 确保生产者线程执行完毕
consumer.join()  # 确保消费者线程执行完毕

print("All tasks completed.")
```

在这个例子中，我们定义了两个线程类：`Producer` 和 `Consumer`。`Producer` 准备数据并在数据准备好后通过调用 `event.set()` 来设置事件。与此同时，`Consumer` 使用 `event.wait()` 方法等待事件被设置。这意味着，`Consumer` 线程会在 `Producer` 线程设置事件之前保持阻塞状态，一旦事件被设置，它就会继续执行后续的数据处理逻辑。

请注意，实际应用中可能需要更复杂的逻辑来处理多次生产与消费，以及事件的重置(`event.clear()`)以便重复使用。上述示例仅为了演示`Event`的基本使用方法。



## 定时器对象 Timer

此类表示一个操作应该在等待一定的时间之后运行 --- 相当于一个定时器。 Timer 类是 Thread 类的子类，因此可以像一个自定义线程一样工作。

与线程一样，通过调用 start() 方法启动定时器。而 cancel() 方法可以停止计时器（在计时结束前）， 定时器在执行其操作之前等待的时间间隔可能与用户指定的时间间隔不完全相同。

```python
class threading.Timer(interval, function, args=None, kwargs=None)
```

创建一个定时器，在经过 interval 秒的间隔事件后，将会用参数 args 和关键字参数 kwargs 调用 function。如果 args 为 None （默认值），则会使用一个空列表。如果 kwargs 为 None （默认值），则会使用一个空字典。



### 方法

- `cancel`()
  - 停止定时器并取消执行计时器将要执行的操作。仅当计时器仍处于等待状态时有效。



### 使用示例

```python
from threading import Timer


def hello():
    print("hello, world")  # 3秒后输出


t = Timer(3, hello)
t.start()
```





```python
import threading
import time


def hello():
    print("hello, world")


if __name__ == "__main__":
    t = threading.Timer(5, function=hello)
    t.start()

    for i in range(1, 4):
        print(i)
        time.sleep(1)
        if i == 3:
            t.cancel()  # 3秒时取消
```





## 栅栏对象 Barrier

`threading.Barrier` 主要功能是确保一组线程能够同时到达某个代码执行点，之后再一起继续执行。换句话说，它创建了一个所有线程必须等待的屏障（Barrier），直到所有线程都到达这个障碍点后，所有线程才会被释放并继续执行。

```python
class threading.Barrier(parties, action=None, timeout=None)
```

创建一个需要 parties 个线程的栅栏对象。如果提供了可调用的 action 参数，它会在所有线程被释放时在其中一个线程中自动调用。 timeout 是默认的超时时间，如果没有在 wait() 方法中指定超时时间的话。



### 方法

- `wait`(*timeout=None*)
  - 冲出栅栏。当栅栏中所有线程都已经调用了这个函数，它们将同时被释放。如果提供了 *timeout* 参数，这里的 *timeout* 参数优先于创建栅栏对象时提供的 *timeout* 参数。
- `reset`()
  - 重置栅栏为默认的初始态。如果栅栏中仍有线程等待释放，这些线程将会收到 `BrokenBarrierError`异常。请注意使用此函数时，如果存在状态未知的其他线程，则可能需要执行外部同步。 如果栅栏已损坏则最好将其废弃并新建一个。
- `abort`()
  - 使栅栏处于损坏状态。这将导致任何现有和未来对 `wait()`的调用失败并引发 `BrokenBarrierError`。 例如可以在需要中止某个线程时使用此方法，以避免应用程序的死锁。更好的方式是：创建栅栏时提供一个合理的超时时间，来自动避免某个线程出错。
- `parties`
  - 冲出栅栏所需要的线程数量。
- `n_waiting`
  - 当前时刻正在栅栏中阻塞的线程数量。
- `broken`
  - 一个布尔值，值为 `True` 表明栅栏为破损态。





### 使用示例

```python
import threading
import time
import random


def worker(barrier, thread_name):
    print(f"{thread_name} 开始执行第一阶段...")
    time.sleep(random.randint(1, 3))  # 模拟不同线程执行时间不同
    barrier.wait()  # 等待所有线程到达此点
    print(f"{thread_name} 开始执行第二阶段...")


def init():
    print(f"{threading.current_thread()} -- init")

# 初始化屏障，这里设置parties为3，表示需要3个线程都调用wait后才能继续
barrier = threading.Barrier(3, action=init)

threads = []
for i in range(3):
    t = threading.Thread(target=worker, args=(barrier, f"Thread-{i+1}"))
    threads.append(t)
    t.start()

# 确保所有线程执行完毕
for t in threads:
    t.join()

print("所有线程执行完毕。")

```







## 队列

queue 模块实现了多生产者、多消费者队列。这特别适用于消息必须安全地在多线程间交换的线程编程。模块中的 Queue 类实现了所有所需的锁定语义。

模块实现了三种类型的队列，它们的区别仅仅是条目取回的顺序。在 FIFO 队列中，先添加的任务先取回。在 LIFO 队列中，最近被添加的条目先取回(操作类似一个堆栈)。优先级队列中，条目将保持排序( 使用 heapq 模块 ) 并且最小值的条目第一个返回。

在内部，这三个类型的队列使用锁来临时阻塞竞争线程；然而，它们并未被设计用于线程的重入性处理。

此外，模块实现了一个 "简单的" FIFO 队列类型， SimpleQueue ，这个特殊实现为小功能在交换中提供额外的保障。





这些类都是Python标准库`queue`模块中定义的不同类型的队列，它们各自有特定的行为和用途：

1. **`queue.Queue(maxsize=0)` - 先进先出（FIFO）队列**:
   这是最基本的队列类型，遵循“先进先出”原则，即最先放入队列的元素也将是最先被移除的元素。`maxsize`参数指定了队列能容纳的最大项目数量。默认值0表示队列大小无限制。当队列满时，如果有新的插入操作，且`block=True`（默认），则插入操作会被阻塞，直到队列中有空间。

2. **`queue.LifoQueue(maxsize=0)` - 后进先出（LIFO）队列**:
   这种队列遵循“后进先出”原则，类似于堆栈，最后放入队列的元素会最先被移除。它也是基于`maxsize`参数来限制队列大小，且同样支持阻塞行为配置。

3. **`queue.PriorityQueue(maxsize=0)` - 优先级队列**:
   优先级队列中的元素会根据它们的优先级被排序。当你从队列中取出元素时，总是会得到当前优先级最高的元素（默认是最小的那个）。优先级可以通过元组中的第一个元素来确定，这个元素越小，优先级越高。此队列同样支持`maxsize`参数来限制队列大小，并可以配置阻塞行为。

4. **`queue.SimpleQueue` - 简化的队列**:
   `SimpleQueue`是在Python 3.7中引入的一个简化版本的队列，它的设计目标是为了在不需要复杂功能（如优先级排序或最大大小限制）时，提供一个更轻量级、更高效的队列实现。它默认不允许设置`maxsize`，意味着队列大小是不受限的，并且总是阻塞的，即在队列为空时尝试获取元素，或队列满时尝试放入元素，都会阻塞等待。

总结来说，选择哪种队列类型取决于你的具体需求：是否需要特定的元素取出顺序（FIFO、LIFO或优先级）、是否需要限制队列大小、以及是否有特殊的性能或简洁性要求。



`Queue`方法说明：

- **Queue.qsize()**: 返回队列的大致大小。
- **Queue.empty()**: 如果队列为空，返回True；否则返回False。
- **Queue.full()**: 如果队列已满，返回True；否则返回False。
- **Queue.put(item, block=True, timeout=None)**: 将item放入队列，可选阻塞与超时控制。
- **Queue.put_nowait(item)**: 相当于put(item, False)，非阻塞放入。
- **Queue.get(block=True, timeout=None)**: 从队列移除并返回一个项目，支持阻塞与超时控制。
- **Queue.get_nowait()**: 相当于get(False)，非阻塞获取。
- **Queue.task_done()**: 表示完成一个获取的任务，用于消费者线程。
- **Queue.join()**: 阻塞直到队列中所有元素被接收和处理完毕。



`SimpleQueue`方法说明：

- **SimpleQueue.qsize()**: 返回队列的大致大小，注意非阻塞性质。
- **SimpleQueue.empty()**: 判断队列是否为空，返回True或False，不保证get()行为。
- **SimpleQueue.put(item, block=True, timeout=None)**: 放入item到队列，永不阻塞，block与timeout参数被忽略。
- **SimpleQueue.put_nowait(item)**: 相当于put(item)，用于兼容性，总是非阻塞。
- **SimpleQueue.get(block=True, timeout=None)**: 获取并移除队列项目，支持阻塞与超时控制。
- **SimpleQueue.get_nowait()**: 非阻塞获取队列项目，与get(False)等效。



示例

```python
import threading, queue

q = queue.Queue()


def worker():
    while True:
        item = q.get()
        print(f"Working on {item}")
        print(f"Finished {item}")
        q.task_done()


threading.Thread(target=worker, daemon=True).start()

for item in range(3):
    q.put(item)
print("All task requests sent\n", end="")

q.join()
print("All work completed")

```





### block=False适用场景

`block=False` 参数在 `Queue.put(item, block=False, timeout=None)` 方法中用于控制当队列满时程序的行为。如果设置为 `False`，这意味着当你尝试向一个已经满了的队列添加一个新项目（`item`）时，Python 不会阻塞（即等待），而是立即抛出一个 `queue.Full` 异常。

这种场景适用于以下几种情况：

1. **非阻塞性操作**：当你不希望因为队列满而导致整个程序暂停执行，而是希望程序能够立即响应并处理这种情况时。比如，在高实时性要求的系统中，你可能不希望任何部分因为等待而耽误时间。

2. **资源管理与错误处理**：你可以结合异常处理机制来优雅地处理队列满的情况，比如记录日志、丢弃数据、或者调整其他部分的程序行为以适应当前状况。

3. **生产者-消费者模型的流量控制**：在多线程或多进程的生产者-消费者模型中，如果生产速度远大于消费速度，导致队列频繁满溢，可以通过设置 `block=False` 配合合适的错误处理逻辑，来实现对生产速率的间接调控，避免无限制地消耗系统资源。

4. **超时替代方案**：虽然问题中提到 `timeout` 参数未使用，但提及 `block=False` 的场景时，也常对比提及使用 `timeout` 来设定等待时间上限的情况。当明确不希望等待，直接失败比等待更符合需求时，直接使用 `block=False` 更为直接和高效。

综上所述，`block=False` 主要适用于需要程序对队列满这一事件做出快速响应，避免阻塞，并通过异常处理机制来灵活管理程序流程的场景。





### queue模块和第三方消息队列系统区别

1. **设计目的**：`queue` 模块主要是为了解决同一进程内或通过多线程间的数据同步问题。它提供了一种线程安全的方式来在生产者和消费者线程之间传递数据。
2. **应用场景**：适用于单机环境下的多线程编程，特别是在需要线程间协作和同步的场景中，如数据处理、任务分配等。
3. 功能特性：
   - 提供多种队列类型，如 `FIFO`（先入先出）、`LIFO`（后入先出）、优先级队列等。
   - 内置线程安全，无需担心并发访问问题。
   - 支持阻塞和非阻塞操作，以及超时设置。
4. **扩展性**：受限于其设计，`queue` 模块不支持跨网络通信，也不易于扩展到分布式系统中。







# 多进程 multiprocessing

multiprocessing 是一个支持使用与 threading 模块类似的 API 来产生进程的包。 multiprocessing 包同时提供了本地和远程并发操作，通过使用子进程而非线程有效地绕过了 全局解释器锁。 因此，multiprocessing 模块允许程序员充分利用给定机器上的多个处理器。 它在 Unix 和 Windows 上均可运行。





示例

```python
from multiprocessing import Process
import os


def info(title):
    print(title)
    print("module name:", __name__)
    print("parent process:", os.getppid())
    print("process id:", os.getpid())


def f(name):
    info("function f")
    print("hello", name)


if __name__ == "__main__":
    info("main line")
    p = Process(target=f, args=("bob",))
    p.start()
    p.join()

```







# 启动并行任务



## 线程池 ThreadPoolExecutor

`ThreadPoolExecutor` 是 Python 中用于创建线程池的一个类，它位于 `concurrent.futures` 模块中。线程池允许你以并发方式执行可调用对象（如函数），而无需手动管理线程的创建和加入。



参数说明：

- `max_workers `
  - 默认值已改为 `min(32, os.cpu_count() + 4)`。 这个默认值会保留至少 5 个工作线程用于 I/O 密集型任务。 对于那些释放了 GIL 的 CPU 密集型任务，它最多会使用 32 个 CPU 核心。这样能够避免在多核机器上不知不觉地使用大量资源。

- `thread_name_prefix`
  - 线程名前缀。默认为`ThreadPoolExecutor-`。

- `initializer`
  - 可调用的对象（如函数），每个工作线程启动时被调用。
- `initargs`
  - 元组，传入initializer的参数。



```python
import concurrent.futures
import time
import threading


# 初始化
def init_func(value):
    print(f"{threading.current_thread()} -- 初始化: {value}")


# 一个模拟耗时操作的函数
def long_running_task(n):
    print(f"{threading.current_thread()} -- Task {n} started")
    time.sleep(n)  # 模拟耗时操作
    print(f"{threading.current_thread()} -- Task {n} finished")
    return n * n


# 创建一个线程池，最大线程数为3
with concurrent.futures.ThreadPoolExecutor(
    max_workers=3, thread_name_prefix="MyThreadPool-", initializer=init_func, initargs=("app.log",)
) as executor:
    print(f"线程数: {executor._max_workers}")

    # 提交任务到线程池并保留Future对象
    futures = {executor.submit(long_running_task, n) for n in range(5)}

    # 收集结果
    for future in concurrent.futures.as_completed(futures):
        result = future.result()
        print(f"Result: {result}")

```









## 进程池 ProcessPoolExecutor



`concurrent.futures.ProcessPoolExecutor` 是 Python 标准库中的一个类，用于创建一个基于进程的并行执行环境。它允许你利用多核CPU通过子进程执行可并行的任务。下面是其构造函数参数的详细说明：

1. **max_workers**:
   - **作用**: 指定可以同时运行的进程数（工作者进程）。这个参数决定了并发执行任务的最大并行度。
   - **默认值**: 如果未指定，默认值通常是 `os.cpu_count()` 的结果，即系统上可用的处理器核心数。
   - **注意事项**: 设置过大的值可能会导致资源竞争加剧，降低效率或因资源耗尽而引发问题。

2. **mp_context**:
   - **作用**: 允许自定义一个 `multiprocessing.context.BaseContext` 实例来控制进程的创建方式和上下文。这可以用来定制进程间通信的细节，比如使用不同的启动方法或改变进程间的同步机制。
   - **默认值**: 如果未提供，默认使用 `multiprocessing` 模块的标准上下文。
   - **使用场景**: 当需要对进程的创建和管理有特殊需求时，比如修改进程的启动方式或共享资源管理。

3. **initializer**:
   - **作用**: 指定一个可调用对象（如函数），该对象将在每个工作者进程启动时被调用一次。
   - **用途**: 可以用来初始化每个进程的全局状态，比如设置日志记录器、加载共享数据或配置环境变量。
   - **参数**: 如果初始化函数需要参数，通过 `initargs` 提供。

4. **initargs**:
   - **作用**: 提供给 `initializer` 函数的额外参数元组。
   - **类型**: 必须是一个元组，即使只有一个参数也是如此。
   - **示例**: 如果你的 `initializer` 需要一个文件路径和一个布尔值，你可以这样设置 `initargs=('path/to/file', True)`。

综上，`ProcessPoolExecutor` 通过这些参数提供了灵活的方式来控制进程池的创建和管理，使得开发者能够根据具体的应用需求调整并行执行策略。







